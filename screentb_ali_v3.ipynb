{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU50QIjQbfrx",
        "outputId": "5df66a4a-e498-4ca4-e77c-54eaecfff5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'tuberculosis-tb-chest-xray-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/tuberculosis-tb-chest-xray-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"tawsifurrahman/tuberculosis-tb-chest-xray-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmentasi Paru dan Lesi"
      ],
      "metadata": {
        "id": "t-A6grXDcGp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage import filters, morphology, measure, exposure, segmentation, feature\n",
        "from scipy.ndimage import binary_fill_holes\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "# Segmentasi Paru\n",
        "\n",
        "# Preprocessing citra menggunakan AHE\n",
        "def img_preprocess(img):\n",
        "    img_u8 = (img * 255).astype(np.uint8)\n",
        "    denoised = cv2.bilateralFilter(img_u8, 9, 75, 75)\n",
        "    img_clean = denoised.astype(np.float32) / 255.0\n",
        "    img_enhanced = exposure.equalize_adapthist(img_clean, clip_limit=0.02)\n",
        "    return img_enhanced\n",
        "\n",
        "# membuat mask tubuh\n",
        "def make_torso_mask(img):\n",
        "    try: thr = filters.threshold_otsu(img)\n",
        "    except: return np.ones_like(img, dtype=np.uint8)\n",
        "    mask = img > thr * 0.5\n",
        "    mask = morphology.remove_small_objects(mask, 5000)\n",
        "    mask = morphology.binary_closing(mask, morphology.disk(5))\n",
        "    mask = binary_fill_holes(mask)\n",
        "    h, w = mask.shape\n",
        "    border_cut = int(w * 0.05)\n",
        "    mask[:, :border_cut] = 0\n",
        "    mask[:, -border_cut:] = 0\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "# mensegmentasi paru pakai k-means clustering (ada di slide bapaknya)\n",
        "def segment_kmeans(img, torso_mask):\n",
        "    if np.sum(torso_mask) == 0: return np.zeros_like(img, dtype=np.uint8)\n",
        "    masked_pixels = img[torso_mask > 0].reshape(-1, 1)\n",
        "    if masked_pixels.shape[0] < 100: return np.zeros_like(img, dtype=np.uint8)\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=5).fit(masked_pixels)\n",
        "    centers = kmeans.cluster_centers_\n",
        "    lung_cluster_label = np.argmin(centers)\n",
        "    labels = kmeans.labels_\n",
        "    full_labels = np.zeros(img.shape, dtype=int)\n",
        "    full_labels[torso_mask > 0] = labels\n",
        "    lung_mask = (full_labels == lung_cluster_label) & (torso_mask > 0)\n",
        "    return lung_mask\n",
        "\n",
        "# menentukan seed (titik awal) watershed\n",
        "def get_clean_seed(raw_mask):\n",
        "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 25))\n",
        "    v_seed = cv2.morphologyEx(raw_mask.astype(np.uint8), cv2.MORPH_OPEN, v_kernel)\n",
        "    try: v_seed = morphology.remove_small_objects(v_seed.astype(bool), 1000)\n",
        "    except: pass\n",
        "    severed_mask = morphology.binary_erosion(raw_mask, morphology.disk(10))\n",
        "    labels = measure.label(severed_mask)\n",
        "    clean_seed = np.zeros_like(raw_mask, dtype=bool)\n",
        "    for region in measure.regionprops(labels):\n",
        "        region_mask = (labels == region.label)\n",
        "        if np.any(region_mask & v_seed):\n",
        "            clean_seed = clean_seed | region_mask\n",
        "    return clean_seed\n",
        "\n",
        "# menentukan batas paru\n",
        "def get_barrier(img, torso_mask, clean_seed):\n",
        "    if np.sum(torso_mask) == 0: return np.zeros_like(img)\n",
        "    bright_thresh = np.percentile(img[torso_mask > 0], 60)\n",
        "    bright_areas = (img > bright_thresh) & (torso_mask > 0)\n",
        "    skeleton = morphology.skeletonize(bright_areas)\n",
        "    img_u8 = (img * 255).astype(np.uint8)\n",
        "    canny_edges = cv2.Canny(img_u8, 40, 120) > 0\n",
        "    raw_barrier = (skeleton | canny_edges)\n",
        "    internal_zone = morphology.binary_dilation(clean_seed, morphology.disk(25))\n",
        "    final_barrier = raw_barrier & (~internal_zone)\n",
        "    bg_outside = (torso_mask == 0)\n",
        "    final_barrier = final_barrier | bg_outside\n",
        "    return final_barrier\n",
        "\n",
        "# menghaluskan mask yang kroak\n",
        "def smoothen_mask(binary_mask):\n",
        "    mask_u8 = (binary_mask * 255).astype(np.uint8)\n",
        "    blurred = cv2.GaussianBlur(mask_u8, (25, 25), 0)\n",
        "    _, smooth_mask = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(smooth_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    final_canvas = np.zeros_like(mask_u8)\n",
        "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:2]\n",
        "    for cnt in contours:\n",
        "        epsilon = 0.003 * cv2.arcLength(cnt, True)\n",
        "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
        "        cv2.drawContours(final_canvas, [approx], -1, 255, -1)\n",
        "    return final_canvas\n",
        "\n",
        "# segmentasi paru dengan segala alat di atasnya\n",
        "def segment_lungs(img_original):\n",
        "    # Pipeline V26 Lengkap\n",
        "    img_resized = cv2.resize(img_original, (512, 512))\n",
        "    img_float = img_resized.astype(np.float32) / 255.0\n",
        "\n",
        "    try:\n",
        "        img_enhanced = img_preprocess(img_float)\n",
        "        torso_mask = make_torso_mask(img_enhanced)\n",
        "        raw_lung = segment_kmeans(img_enhanced, torso_mask)\n",
        "        clean_seed = get_clean_seed(raw_lung)\n",
        "        barrier_map = get_barrier(img_enhanced, torso_mask, clean_seed)\n",
        "\n",
        "        img_smooth = cv2.GaussianBlur(img_enhanced, (3, 3), 0)\n",
        "        elevation_map = filters.sobel(img_smooth)\n",
        "\n",
        "        markers = np.zeros_like(raw_lung, dtype=np.int32)\n",
        "        markers[clean_seed == 1] = 1\n",
        "        markers[barrier_map == 1] = 2\n",
        "\n",
        "        watershed_result = segmentation.watershed(elevation_map, markers)\n",
        "        lung_watershed = (watershed_result == 1)\n",
        "        filled_lung = binary_fill_holes(lung_watershed)\n",
        "\n",
        "        # Convex Smoothing\n",
        "        final_mask = np.zeros_like(raw_lung, dtype=np.uint8)\n",
        "        labels = measure.label(filled_lung)\n",
        "        props = sorted(measure.regionprops(labels), key=lambda x: x.area, reverse=True)[:2]\n",
        "\n",
        "        for prop in props:\n",
        "            single_lung = (labels == prop.label)\n",
        "            chull = morphology.convex_hull_image(single_lung)\n",
        "            reference_shape = morphology.binary_dilation(single_lung, morphology.disk(10))\n",
        "            smoothed_lung = chull & reference_shape\n",
        "            final_mask[smoothed_lung] = 1\n",
        "\n",
        "        final_mask_smooth = smoothen_mask(final_mask)\n",
        "        return final_mask_smooth, img_enhanced # Return img_enhanced untuk dipakai deteksi lesi\n",
        "\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# Deteksi Lesi\n",
        "def detect_lesions(img_enhanced, lung_mask):\n",
        "    \"\"\"\n",
        "    V26 STRICT: Versi konservatif untuk mengurangi False Positive pada paru normal.\n",
        "    Hanya menandai lesi jika BENAR-BENAR yakin (Sangat gelap/Sangat kasar).\n",
        "    \"\"\"\n",
        "    masks = {}\n",
        "    h, w = img_enhanced.shape\n",
        "\n",
        "    # Pastikan mask binary\n",
        "    lung_mask_bool = lung_mask > 0\n",
        "\n",
        "    # Hitung statistik HANYA di dalam paru\n",
        "    roi_pixels = img_enhanced[lung_mask_bool]\n",
        "    if len(roi_pixels) == 0:\n",
        "        return {k: np.zeros_like(lung_mask) for k in ['calcification', 'cavity', 'infiltrate', 'effusion']}\n",
        "\n",
        "    mean_val = np.mean(roi_pixels)\n",
        "    std_val = np.std(roi_pixels)\n",
        "\n",
        "    # Deteksi Calcification (titik sangat terang dan kecil)\n",
        "    thresh_calc = mean_val + 3.0 * std_val\n",
        "    mask_calc = (img_enhanced > thresh_calc) & lung_mask_bool\n",
        "\n",
        "    # Filter ukuran: Kalsifikasi itu bintik kecil, bukan area luas\n",
        "    # Hapus yang terlalu besar (kemungkinan tulang) atau terlalu kecil (noise)\n",
        "    mask_calc = morphology.remove_small_objects(mask_calc, 10) # Min 10 px\n",
        "\n",
        "    # Hapus blob besar (misal > 500 px) karena itu pasti tulang\n",
        "    lbl_calc = measure.label(mask_calc)\n",
        "    for prop in regionprops(lbl_calc):\n",
        "        if prop.area > 500:\n",
        "            mask_calc[lbl_calc == prop.label] = 0\n",
        "\n",
        "    masks['calcification'] = mask_calc\n",
        "\n",
        "    # Deteksi Cacity (area gelap yang bulat)\n",
        "    thresh_dark = mean_val - 1.5 * std_val\n",
        "\n",
        "    # Fokus area atas paru saja (Top 60%)\n",
        "    top_lung = lung_mask_bool.copy()\n",
        "    top_lung[int(h*0.6):, :] = 0\n",
        "\n",
        "    raw_cavity = (img_enhanced < thresh_dark) & top_lung\n",
        "\n",
        "    # Filter Geometri: Cavity TB biasanya bulat/oval. Celah rusuk itu pipih.\n",
        "    # Cek Eccentricity (Kelonjongan). 0=Bulat, 1=Garis.\n",
        "    # Cek Solidity (Kepadatan).\n",
        "    mask_cavity = np.zeros_like(lung_mask)\n",
        "    lbl_cav = measure.label(raw_cavity)\n",
        "\n",
        "    for prop in regionprops(lbl_cav):\n",
        "        # Syarat: Area cukup besar, TIDAK terlalu lonjong (Eccentricity < 0.9), Padat (Solidity > 0.8)\n",
        "        if prop.area > 150 and prop.eccentricity < 0.9 and prop.solidity > 0.85:\n",
        "            mask_cavity[lbl_cav == prop.label] = 1\n",
        "\n",
        "    masks['cavity'] = mask_cavity\n",
        "\n",
        "    # Deteksi Infiltrate (tekstur sangat kasar)\n",
        "    img_u8 = (img_enhanced * 255).astype(np.uint8)\n",
        "    entropy_img = filters.rank.entropy(img_u8, morphology.disk(5), mask=lung_mask)\n",
        "\n",
        "    # Threshold entropy (misal > 5.5). Normal rib cage sekitar 4.0-5.0.\n",
        "    mask_texture = (entropy_img > 5.5) & lung_mask_bool\n",
        "\n",
        "    # Hapus area tulang (calcification mask) dari sini\n",
        "    mask_texture = mask_texture & (~mask_calc)\n",
        "\n",
        "    # Clean up noise bintik\n",
        "    mask_texture = morphology.binary_opening(mask_texture, morphology.disk(3))\n",
        "\n",
        "    masks['infiltrate'] = mask_texture\n",
        "\n",
        "    # Deteksi Effusion (cairan di sudut bawah)\n",
        "    bottom_slice_h = int(h * 0.75)\n",
        "    bottom_lung = lung_mask_bool.copy()\n",
        "    bottom_lung[:bottom_slice_h, :] = 0\n",
        "\n",
        "    effusion_final_mask = np.zeros_like(lung_mask)\n",
        "\n",
        "    if np.sum(bottom_lung) > 0:\n",
        "        # Pisahkan paru kiri dan kanan di area bawah\n",
        "        lbl_bottom = measure.label(bottom_lung)\n",
        "\n",
        "        for region in regionprops(lbl_bottom):\n",
        "            # Abaikan noise kecil\n",
        "            if region.area < 500: continue\n",
        "\n",
        "            single_side_bottom = (lbl_bottom == region.label)\n",
        "\n",
        "            # Hitung Convex Hull per sisi\n",
        "            chull_side = morphology.convex_hull_image(single_side_bottom)\n",
        "\n",
        "            # Kandidat = Selisih Hull dan Mask Asli\n",
        "            candidate = chull_side & (~single_side_bottom)\n",
        "\n",
        "            # FILTERING KETAT:\n",
        "            # 1. Hapus area kecil (< 1500 px)\n",
        "            candidate_big = morphology.remove_small_objects(candidate, 1500)\n",
        "\n",
        "            # 2. Hapus garis tipis dengan Opening\n",
        "            candidate_solid = morphology.binary_opening(candidate_big, morphology.disk(5))\n",
        "\n",
        "            effusion_final_mask = effusion_final_mask | candidate_solid\n",
        "\n",
        "        masks['effusion'] = effusion_final_mask\n",
        "    else:\n",
        "        masks['effusion'] = np.zeros_like(lung_mask)\n",
        "\n",
        "    return masks\n",
        "\n",
        "def create_multi_overlay(original, lung_mask, lesion_masks):\n",
        "    \"\"\"\n",
        "    Membuat overlay warna-warni:\n",
        "    - Paru: Ungu Transparan\n",
        "    - Calcification: Kuning\n",
        "    - Cavity: Merah\n",
        "    - Infiltrate: Biru Cyan\n",
        "    - Effusion: Hijau\n",
        "    \"\"\"\n",
        "    if len(original.shape) == 2:\n",
        "        vis = cv2.cvtColor(original, cv2.COLOR_GRAY2BGR)\n",
        "    else:\n",
        "        vis = original.copy()\n",
        "\n",
        "    # 1. Overlay Paru Dasar (Ungu)\n",
        "    lung_color = (255, 0, 255) # Magenta\n",
        "    overlay_lung = vis.copy()\n",
        "    overlay_lung[lung_mask > 0] = lung_color\n",
        "    vis = cv2.addWeighted(overlay_lung, 0.3, vis, 0.7, 0)\n",
        "\n",
        "    # 2. Overlay Lesi (Lebih Solid)\n",
        "    # Urutan penting: Lesi kecil ditumpuk di atas lesi besar\n",
        "\n",
        "    # Infiltrate (Cyan)\n",
        "    if np.sum(lesion_masks['infiltrate']) > 0:\n",
        "        vis[lesion_masks['infiltrate'] > 0] = (255, 255, 0) # Cyan (B,G,R)\n",
        "\n",
        "    # Effusion (Hijau)\n",
        "    if np.sum(lesion_masks['effusion']) > 0:\n",
        "        vis[lesion_masks['effusion'] > 0] = (0, 255, 0) # Green\n",
        "\n",
        "    # Calcification (Kuning)\n",
        "    if np.sum(lesion_masks['calcification']) > 0:\n",
        "        vis[lesion_masks['calcification'] > 0] = (0, 255, 255) # Yellow\n",
        "\n",
        "    # Cavity (Merah)\n",
        "    if np.sum(lesion_masks['cavity']) > 0:\n",
        "        vis[lesion_masks['cavity'] > 0] = (0, 0, 255) # Red\n",
        "\n",
        "    return vis\n",
        "\n",
        "# Batch Running\n",
        "\n",
        "input_root = \"/kaggle/input/tuberculosis-tb-chest-xray-dataset\"\n",
        "output_vis_root = \"lesion_segmentation_results\"\n",
        "\n",
        "categories = ['NORMAL', 'TUBERCULOSIS']\n",
        "\n",
        "print(f\"=== MULTI-LESION SEGMENTATION BATCH ===\")\n",
        "\n",
        "for category in categories:\n",
        "    input_dir = os.path.join(input_root, category)\n",
        "    save_dir = os.path.join(output_vis_root, category)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Ambil list gambar\n",
        "    extensions = ['*.png', '*.jpg', '*.jpeg', '*.PNG']\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(input_dir, ext)))\n",
        "\n",
        "    print(f\"\\nProcessing {category} ({len(image_files)} images)...\")\n",
        "\n",
        "    for img_path in tqdm(image_files):\n",
        "        try:\n",
        "            filename = os.path.basename(img_path)\n",
        "\n",
        "            # 1. Load & Segmentasi Paru\n",
        "            img_original = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img_original is None: continue\n",
        "\n",
        "            mask_lung, img_enhanced = segment_lungs(img_original)\n",
        "\n",
        "            if mask_lung is not None:\n",
        "                # 2. Deteksi Lesi\n",
        "                lesion_masks = detect_lesions(img_enhanced, mask_lung)\n",
        "\n",
        "                # 3. Visualisasi\n",
        "                img_disp = cv2.resize(img_original, (512, 512))\n",
        "                final_vis = create_multi_overlay(img_disp, mask_lung, lesion_masks)\n",
        "\n",
        "                # Simpan\n",
        "                cv2.imwrite(os.path.join(save_dir, filename), final_vis)\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "print(\"\\nSelesai! Cek folder:\", output_vis_root)"
      ],
      "metadata": {
        "id": "vRyoR5JnbuS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekstraksi Fitur"
      ],
      "metadata": {
        "id": "YaaRMtCDb-bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import skew, kurtosis\n",
        "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "# Fungsi Ekstraksi Fitur\n",
        "def extract_intensity_features(img, mask):\n",
        "    \"\"\"\n",
        "    Mengambil statistik intensitas piksel HANYA di dalam area paru.\n",
        "    Berguna untuk: Calcification (Putih Terang), Consolidation (Abu Terang).\n",
        "    \"\"\"\n",
        "    # Ambil piksel di dalam mask\n",
        "    roi_pixels = img[mask > 0]\n",
        "\n",
        "    if len(roi_pixels) == 0:\n",
        "        return [0] * 6 # Return 0 jika mask kosong\n",
        "\n",
        "    # Statistik Dasar\n",
        "    mean_val = np.mean(roi_pixels)\n",
        "    std_val = np.std(roi_pixels)\n",
        "    max_val = np.max(roi_pixels)\n",
        "    min_val = np.min(roi_pixels)\n",
        "\n",
        "    # Statistik Distribusi (Penting untuk Kalsifikasi)\n",
        "    skewness_val = skew(roi_pixels) # Ekor distribusi (apakah ada sedikit piksel sangat putih?)\n",
        "    kurtosis_val = kurtosis(roi_pixels) # Keruncingan histogram\n",
        "\n",
        "    return [mean_val, std_val, max_val, min_val, skewness_val, kurtosis_val]\n",
        "\n",
        "def extract_glcm_features(img, mask):\n",
        "    \"\"\"\n",
        "    Mengambil fitur tekstur (Kasar/Halus).\n",
        "    Berguna untuk: Infiltrate (Kasar), Fibrotic (Berserabut).\n",
        "    \"\"\"\n",
        "    # GLCM butuh integer (uint8). Kita quantize ke 64 level biar cepat & robust noise.\n",
        "    img_u8 = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Masking: Area luar paru kita set ke 0.\n",
        "    # Agar GLCM tidak menghitung tekstur background, kita potong bounding box paru saja.\n",
        "    rows, cols = np.where(mask > 0)\n",
        "    if len(rows) == 0: return [0] * 5\n",
        "\n",
        "    y1, y2 = np.min(rows), np.max(rows)\n",
        "    x1, x2 = np.min(cols), np.max(cols)\n",
        "\n",
        "    # Crop ke ROI paru\n",
        "    roi_img = img_u8[y1:y2, x1:x2]\n",
        "\n",
        "    # Hitung GLCM (Jarak 1 piksel, 4 arah sudut: 0, 45, 90, 135 derajat)\n",
        "    glcm = graycomatrix(roi_img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
        "                        levels=256, symmetric=True, normed=True)\n",
        "\n",
        "    # Properti GLCM (Rata-rata dari 4 sudut)\n",
        "    contrast = np.mean(graycoprops(glcm, 'contrast'))\n",
        "    dissimilarity = np.mean(graycoprops(glcm, 'dissimilarity'))\n",
        "    homogeneity = np.mean(graycoprops(glcm, 'homogeneity'))\n",
        "    energy = np.mean(graycoprops(glcm, 'energy'))\n",
        "    correlation = np.mean(graycoprops(glcm, 'correlation'))\n",
        "\n",
        "    return [contrast, dissimilarity, homogeneity, energy, correlation]\n",
        "\n",
        "def extract_lbp_features(img, mask):\n",
        "    \"\"\"\n",
        "    Local Binary Pattern: Menangkap pola mikro-tekstur.\n",
        "    Berguna untuk: Fibrosis detail.\n",
        "    \"\"\"\n",
        "    img_u8 = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Parameter LBP standar\n",
        "    radius = 1\n",
        "    n_points = 8 * radius\n",
        "\n",
        "    # Hitung LBP\n",
        "    lbp = local_binary_pattern(img_u8, n_points, radius, method='uniform')\n",
        "\n",
        "    # Ambil histogram LBP hanya di dalam mask\n",
        "    lbp_roi = lbp[mask > 0]\n",
        "\n",
        "    if len(lbp_roi) == 0: return [0] * 10\n",
        "\n",
        "    # Histogram LBP (n_points + 2 bins untuk metode uniform)\n",
        "    n_bins = int(lbp_roi.max() + 1)\n",
        "    hist, _ = np.histogram(lbp_roi, bins=n_bins, range=(0, n_bins), density=True)\n",
        "\n",
        "    # Kita ambil 10 bin pertama sebagai fitur (atau statistik dari histogram)\n",
        "    # Agar vektor fitur konsisten panjangnya, kita ambil statistik histogramnya\n",
        "    # Atau ambil 10 bin pertama (uniform patterns)\n",
        "    features = list(hist[:10])\n",
        "\n",
        "    # Padding jika bin kurang dari 10\n",
        "    if len(features) < 10:\n",
        "        features += [0] * (10 - len(features))\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_shape_features(mask):\n",
        "    \"\"\"\n",
        "    Mengambil geometri bentuk paru.\n",
        "    Berguna untuk: Effusion (Sudut tumpul mengurangi Solidity), Collapse.\n",
        "    \"\"\"\n",
        "    # Labeling (bisa jadi ada 2 paru terpisah)\n",
        "    lbl_mask = measure.label(mask)\n",
        "    props = regionprops(lbl_mask)\n",
        "\n",
        "    if not props: return [0] * 5\n",
        "\n",
        "    # Ambil properti dari region terbesar (atau rata-rata 2 terbesar)\n",
        "    # Di sini kita ambil total area dan rata-rata properti bentuk\n",
        "    total_area = 0\n",
        "    solidity_list = []\n",
        "    extent_list = []\n",
        "    eccentricity_list = []\n",
        "    perimeter_list = []\n",
        "\n",
        "    for prop in props:\n",
        "        total_area += prop.area\n",
        "        solidity_list.append(prop.solidity)       # Kekompakan (Convexity)\n",
        "        extent_list.append(prop.extent)           # Rasio area terhadap bounding box\n",
        "        eccentricity_list.append(prop.eccentricity) # Kelonjongan\n",
        "        perimeter_list.append(prop.perimeter)\n",
        "\n",
        "    # Agregasi (Weighted Average berdasarkan area bisa lebih akurat, tapi Mean simpel cukup)\n",
        "    feat_solidity = np.mean(solidity_list)\n",
        "    feat_extent = np.mean(extent_list)\n",
        "    feat_eccentricity = np.mean(eccentricity_list)\n",
        "\n",
        "    # Compactness (Roundness): 4*pi*Area / Perimeter^2\n",
        "    total_perimeter = np.sum(perimeter_list)\n",
        "    if total_perimeter == 0: feat_compactness = 0\n",
        "    else: feat_compactness = (4 * np.pi * total_area) / (total_perimeter ** 2)\n",
        "\n",
        "    return [total_area, feat_solidity, feat_extent, feat_eccentricity, feat_compactness]\n",
        "\n",
        "def extract_hog_features(img, mask):\n",
        "    \"\"\"\n",
        "    HOG menangkap arah gradien (tepi).\n",
        "    Berguna untuk: Cavity (Lingkaran) dan Infiltrate Edge.\n",
        "    \"\"\"\n",
        "    img_resized = cv2.resize(img, (128, 128)) # Resize kecil untuk HOG global\n",
        "\n",
        "    # Hitung HOG\n",
        "    fd = hog(img_resized, orientations=8, pixels_per_cell=(16, 16),\n",
        "             cells_per_block=(1, 1), visualize=False)\n",
        "\n",
        "    # HOG menghasilkan ribuan fitur. Untuk SVM standar (bukan Deep Learning),\n",
        "    # ringkas menjadi statistik HOG agar tidak overfitting.\n",
        "    hog_mean = np.mean(fd)\n",
        "    hog_std = np.std(fd)\n",
        "    hog_max = np.max(fd)\n",
        "    hog_kurtosis = kurtosis(fd)\n",
        "\n",
        "    return [hog_mean, hog_std, hog_max, hog_kurtosis]\n",
        "\n",
        "# BATCH EXTRACTION PIPELINE\n",
        "def process_dataset(image_dir, mask_dir, categories):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    print(\"Mulai Ekstraksi Fitur...\")\n",
        "\n",
        "    for category in categories:\n",
        "        img_folder = os.path.join(image_dir, category)\n",
        "        msk_folder = os.path.join(mask_dir, category)\n",
        "\n",
        "        # Ambil list file\n",
        "        image_files = glob.glob(os.path.join(img_folder, \"*.*\"))\n",
        "        image_files = [f for f in image_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        print(f\"\\nProcessing Class: {category} ({len(image_files)} images)\")\n",
        "\n",
        "        for img_path in tqdm(image_files):\n",
        "            try:\n",
        "                filename = os.path.basename(img_path)\n",
        "                mask_name = os.path.splitext(filename)[0] + \".png\" # Mask selalu PNG\n",
        "                mask_path = os.path.join(msk_folder, mask_name)\n",
        "\n",
        "                # 1. Load Image & Mask\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if img is None: continue\n",
        "\n",
        "                # Jika mask tidak ditemukan (gagal segmentasi), skip atau handle\n",
        "                if mask is None:\n",
        "                    # print(f\"Warning: Mask not found for {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Resize image agar sama dengan mask (512x512 dari proses sebelumnya)\n",
        "                img = cv2.resize(img, (512, 512))\n",
        "                # Pastikan mask binary\n",
        "                _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                # Normalize Image (0-1 float)\n",
        "                img_float = img.astype(np.float32) / 255.0\n",
        "\n",
        "                # 2. EXTRACT FEATURES\n",
        "                # A. Intensity (6)\n",
        "                f_intensity = extract_intensity_features(img_float, mask)\n",
        "\n",
        "                # B. GLCM Texture (5)\n",
        "                f_glcm = extract_glcm_features(img_float, mask)\n",
        "\n",
        "                # C. LBP Texture (10)\n",
        "                f_lbp = extract_lbp_features(img_float, mask)\n",
        "\n",
        "                # D. Shape (5)\n",
        "                f_shape = extract_shape_features(mask)\n",
        "\n",
        "                # E. HOG (4) - Kita pakai img_float yang di mask\n",
        "                # Masking image untuk HOG (background jadi hitam)\n",
        "                img_masked = img_float.copy()\n",
        "                img_masked[mask == 0] = 0\n",
        "                f_hog = extract_hog_features(img_masked, mask)\n",
        "\n",
        "                # 3. COMBINE\n",
        "                # Label: 0 untuk Normal, 1 untuk Tuberculosis\n",
        "                label = 0 if category == \"Normal\" else 1\n",
        "\n",
        "                row = [filename, label] + f_intensity + f_glcm + f_lbp + f_shape + f_hog\n",
        "                data.append(row)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return data\n",
        "\n",
        "# --- SETUP PATH ---\n",
        "dataset_images_path = \"../tb-chest-xray-classifier/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/versions/3/TB_Chest_Radiography_Database\"          # Folder: Normal, Tuberculosis\n",
        "dataset_masks_path = \"masks_v26\"\n",
        "\n",
        "categories = ['Normal', 'Tuberculosis']\n",
        "\n",
        "# --- RUN ---\n",
        "extracted_data = process_dataset(dataset_images_path, dataset_masks_path, categories)\n",
        "\n",
        "# --- SAVE TO CSV ---\n",
        "# Definisikan nama kolom\n",
        "columns = ['filename', 'label']\n",
        "columns += ['mean', 'std', 'max', 'min', 'skew', 'kurt'] # Intensity\n",
        "columns += ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'] # GLCM\n",
        "columns += [f'lbp_{i}' for i in range(10)] # LBP\n",
        "columns += ['area', 'solidity', 'extent', 'eccentricity', 'compactness'] # Shape\n",
        "columns += ['hog_mean', 'hog_std', 'hog_max', 'hog_kurt'] # HOG\n",
        "\n",
        "df = pd.DataFrame(extracted_data, columns=columns)\n",
        "\n",
        "# Simpan\n",
        "output_csv = \"cxr_tb_features_v1.csv\"\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"\\nSelesai! Fitur tersimpan di {output_csv}\")\n",
        "print(f\"Total Data: {len(df)}\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "2uUgneuDb78F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "wHsaXeSzcZ8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "# Tambahkan precision_score, recall_score, f1_score di sini\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "\n",
        "# PERSIAPAN DATA\n",
        "\n",
        "# Load Data\n",
        "csv_path = \"cxr_tb_features_v1.csv\"\n",
        "print(f\"Loading data from {csv_path}...\")\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Cek data kosong/NaN\n",
        "print(f\"Jumlah NaN sebelum cleaning: {df.isnull().sum().sum()}\")\n",
        "df = df.dropna()\n",
        "\n",
        "# Pisahkan Fitur (X) dan Target (y)\n",
        "X = df.drop(['filename', 'label'], axis=1)\n",
        "y = df['label'] # 0 = Normal, 1 = Tuberculosis\n",
        "\n",
        "print(f\"\\nDistribusi Kelas:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# PIPELINE PRAPEMROSESAN\n",
        "\n",
        "# A. Imputasi\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# B. Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# TRAINING DENGAN GRID SEARCH\n",
        "\n",
        "print(\"\\nMemulai Hyperparameter Tuning (Mencari setting terbaik)...\")\n",
        "\n",
        "# Definisi Parameter\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "# Inisialisasi SVM dengan class_weight balanced\n",
        "svm = SVC(class_weight='balanced', probability=True, random_state=42)\n",
        "\n",
        "# Grid Search (Optimasi berdasarkan F1-Macro agar adil untuk kedua kelas)\n",
        "grid = GridSearchCV(svm, param_grid, refit=True, verbose=2, cv=5, scoring='f1_macro')\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\nParameter Terbaik: {grid.best_params_}\")\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# EVALUASI LENGKAP\n",
        "\n",
        "print(\"\\nEvaluasi pada Test Set...\")\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# --- HITUNG METRIK UTAMA SECARA EKSPLISIT ---\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "# Kita fokus pada kelas 1 (Tuberculosis) untuk F1 Score\n",
        "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "prec = precision_score(y_test, y_pred, pos_label=1)\n",
        "rec = recall_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"HASIL PERFORMA MODEL\")\n",
        "print(\"=\"*30)\n",
        "print(f\"Akurasi (Accuracy)  : {acc*100:.2f}%\")\n",
        "print(f\"F1-Score (TB Class) : {f1*100:.2f}%\")\n",
        "print(f\"Precision (TB Class): {prec*100:.2f}%\")\n",
        "print(f\"Recall (TB Class)   : {rec*100:.2f}%\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# A. Classification Report (Detail per kelas)\n",
        "print(\"\\n--- Detailed Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Normal', 'Tuberculosis']))\n",
        "\n",
        "# B. Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'TB'], yticklabels=['Normal', 'TB'])\n",
        "plt.xlabel('Prediksi Model')\n",
        "plt.ylabel('Kenyataan (Ground Truth)')\n",
        "plt.title(f'Confusion Matrix\\nF1 Score: {f1:.2f}') # Menampilkan F1 di Judul Plot\n",
        "plt.show()\n",
        "\n",
        "# C. ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# SIMPAN MODEL\n",
        "joblib.dump(best_model, 'svm_tb_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "print(\"\\nModel dan Scaler telah disimpan!\")"
      ],
      "metadata": {
        "id": "ZDLkDxSQcau_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "zR26-6GOcfoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from skimage import exposure\n",
        "\n",
        "# LOAD MODEL\n",
        "try:\n",
        "    scaler = joblib.load('scaler.pkl')\n",
        "    model = joblib.load('svm_tb_model.pkl')\n",
        "    print(\"âœ… Model & Scaler berhasil dimuat.\")\n",
        "except:\n",
        "    print(\"âŒ Gagal memuat model. Pastikan file .pkl ada di folder ini.\")\n",
        "\n",
        "# FUNGSI HITUNG PERSENTASE LESI\n",
        "def calculate_lesion_stats(lung_mask, lesion_masks):\n",
        "    \"\"\"\n",
        "    Menghitung berapa persen area paru yang tertutup oleh setiap jenis lesi.\n",
        "    \"\"\"\n",
        "    total_lung_area = np.sum(lung_mask > 0)\n",
        "    stats = {}\n",
        "\n",
        "    if total_lung_area == 0:\n",
        "        return {k: 0.0 for k in lesion_masks.keys()}\n",
        "\n",
        "    for lesion_name, l_mask in lesion_masks.items():\n",
        "        lesion_area = np.sum(l_mask > 0)\n",
        "        percentage = (lesion_area / total_lung_area) * 100\n",
        "        stats[lesion_name] = percentage\n",
        "\n",
        "    return stats\n",
        "\n",
        "# FUNGSI UTAMA TESTING\n",
        "def test_and_visualize(image_path):\n",
        "    # A. Load & Preprocess\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Gagal membaca {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Resize & Float\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    img_float = img.astype(np.float32) / 255.0\n",
        "\n",
        "    # B. Segmentasi Paru (V26)\n",
        "    mask_lung, img_enhanced = segment_lungs(img)\n",
        "\n",
        "    if mask_lung is None:\n",
        "        print(\"Segmentasi Paru Gagal.\")\n",
        "        return\n",
        "\n",
        "    # Normalize mask\n",
        "    _, mask_bin = cv2.threshold(mask_lung, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # C. Ekstraksi Fitur -> urutannya harus sama dengan training\n",
        "    f_int = extract_intensity_features(img_float, mask_bin)\n",
        "    f_glcm = extract_glcm_features(img_float, mask_bin)\n",
        "    f_lbp = extract_lbp_features(img_float, mask_bin)\n",
        "    f_shp = extract_shape_features(mask_bin)\n",
        "\n",
        "    img_masked = img_float.copy()\n",
        "    img_masked[mask_bin == 0] = 0\n",
        "    f_hog = extract_hog_features(img_masked, mask_bin)\n",
        "\n",
        "    features = f_int + f_glcm + f_lbp + f_shp + f_hog\n",
        "    features_vector = np.array(features).reshape(1, -1)\n",
        "\n",
        "    # D. Prediksi SVM\n",
        "    features_scaled = scaler.transform(features_vector)\n",
        "    prediction = model.predict(features_scaled)[0] # 0=Normal, 1=TB\n",
        "    proba = model.predict_proba(features_scaled)[0] # [Prob_Normal, Prob_TB]\n",
        "\n",
        "    confidence = proba[prediction] * 100\n",
        "    label_str = \"Tuberculosis\" if prediction == 1 else \"Normal\"\n",
        "    color_code = 'red' if prediction == 1 else 'green'\n",
        "\n",
        "    # E. Deteksi Lesi & Overlay (Hanya jika TB)\n",
        "    lesion_masks = None\n",
        "    lesion_stats = {}\n",
        "\n",
        "    if prediction == 1:\n",
        "        # Deteksi Lesi (Strict Mode)\n",
        "        lesion_masks = detect_lesions(img_enhanced, mask_bin)\n",
        "        # Hitung Persentase\n",
        "        lesion_stats = calculate_lesion_stats(mask_bin, lesion_masks)\n",
        "        # Buat Overlay Warna-warni\n",
        "        overlay_img = create_multi_overlay(img, mask_bin, lesion_masks)\n",
        "    else:\n",
        "        # Jika Normal, hanya overlay ungu transparan (Paru sehat)\n",
        "        overlay_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "        lung_color = (255, 0, 255)\n",
        "        temp = overlay_img.copy()\n",
        "        temp[mask_bin > 0] = lung_color\n",
        "        overlay_img = cv2.addWeighted(temp, 0.3, overlay_img, 0.7, 0)\n",
        "\n",
        "    # F. VISUALISASI MATPLOTLIB\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Plot 1: Asli\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Citra Asli\\n({os.path.basename(image_path)})\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot 2: Hasil AI\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Convert BGR (OpenCV) to RGB (Matplotlib)\n",
        "    plt.imshow(cv2.cvtColor(overlay_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Prediksi: {label_str}\\nConfidence: {confidence:.2f}%\",\n",
        "              color=color_code, fontweight='bold', fontsize=14)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Tampilkan Statistik Lesi di bawah gambar\n",
        "    if prediction == 1:\n",
        "        stat_text = (\n",
        "            f\"DETEKSI LESI (Persentase Area Paru):\\n\"\n",
        "            f\"ðŸ”µ Infiltrate/Fibrosis : {lesion_stats.get('infiltrate', 0):.2f}%\\n\"\n",
        "            f\"ðŸ”´ Cavity (Lubang)     : {lesion_stats.get('cavity', 0):.2f}%\\n\"\n",
        "            f\"ðŸŸ¡ Calcification       : {lesion_stats.get('calcification', 0):.2f}%\\n\"\n",
        "            f\"ðŸŸ¢ Effusion (Cairan)   : {lesion_stats.get('effusion', 0):.2f}%\"\n",
        "        )\n",
        "        plt.figtext(0.5, 0.01, stat_text, ha=\"center\", fontsize=12,\n",
        "                    bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
        "    else:\n",
        "        plt.figtext(0.5, 0.05, \"âœ… Paru-paru Normal. Tidak ada lesi signifikan terdeteksi.\",\n",
        "                    ha=\"center\", fontsize=12, color='green',\n",
        "                    bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# EKSEKUSI PADA SAMPEL TESTING\n",
        "# Ganti list ini dengan path file testing\n",
        "test_images = [\n",
        "    \"Dataset/Tuberculosis/Tuberculosis-10.png\", # Ganti dengan path file yang benar\n",
        "    \"Dataset/Normal/Normal-15.png\",\n",
        "    # Tambahkan file lain...\n",
        "]\n",
        "\n",
        "# Atau scan folder testing otomatis\n",
        "# test_images = glob.glob(\"Dataset/Test_Set/*.png\")[:5]\n",
        "\n",
        "print(f\"Memulai Testing pada {len(test_images)} gambar...\\n\")\n",
        "\n",
        "for img_path in test_images:\n",
        "    if os.path.exists(img_path):\n",
        "        test_and_visualize(img_path)\n",
        "    else:\n",
        "        print(f\"File tidak ditemukan: {img_path}\")"
      ],
      "metadata": {
        "id": "amP49s2bcgUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}